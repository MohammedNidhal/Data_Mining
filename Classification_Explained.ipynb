{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOiHNmgGAgpz"
      },
      "outputs": [],
      "source": [
        "#Getting set up\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut, cross_val_score, LearningCurveDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "df = pd.read_csv('CSVFile.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "T8tXJV6rOnqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Descriptive statistics\n",
        "heart_df.describe()"
      ],
      "metadata": {
        "id": "2vjL8k_GOstj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking if the dataset is balanced or unbalanced\n",
        "heart_df['target'].value_counts()"
      ],
      "metadata": {
        "id": "u9lcMKcXOsrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If it is unbaanced we will need to make it balanced by reducing number of samples in the greater class (That has the higher number of rows)"
      ],
      "metadata": {
        "id": "wWVDyO6XOyTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x= df.iloc[:, :-1]\n",
        "y= df[\"target\"]\n",
        "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "XnSn7npROspY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deviding data into train test . so we can evaluate the model performance\n",
        "\n",
        "The traget column name can be changed as we will be dealing with who know what (target can be class , or binary choice etc)"
      ],
      "metadata": {
        "id": "huQVzDotO_kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree Classifier\n",
        "model1 = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, random_state=42) #default values\n",
        "model1.fit(x_train, y_train)\n",
        "y_pred = model1.predict(x_test)"
      ],
      "metadata": {
        "id": "jQiw0PGXOsnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the decision tree clasifier\n",
        "criteration can be changhed to Entropy"
      ],
      "metadata": {
        "id": "oe4mamkgPVoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "OPQ8IPcLOskX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculating Accuracy to evalate our model\n",
        "**Exercise 2:**\n",
        "\n",
        "metrics values?\n",
        "\n",
        " Precision= TP/(FP+TP)\n",
        "\n",
        " Recall= TP/(FN+TP)\n",
        "\n",
        " F1-Score=2Ã— Precision*Recall/(Precision+Recall)\n",
        "\n",
        " Support=TP+FN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4NM6j4KkQyj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree visualization\n",
        "plot_tree(model1)"
      ],
      "metadata": {
        "id": "kY7z-wnDOsiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A visual representation of the process of tree clasification"
      ],
      "metadata": {
        "id": "OnMoh0KBRIsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion matrix\n",
        "conf_matrix=confusion_matrix(y_test,y_pred)\n",
        "print('Confusion Matrix:')\n",
        "pd.DataFrame(conf_matrix, columns=list(range(0,2)))"
      ],
      "metadata": {
        "id": "i-vEJv1FOsfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using confusion Matrix to better understand our metrics:\n",
        "\n",
        "The confusion Matrix is not the best"
      ],
      "metadata": {
        "id": "8Izf7nrjRO3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#10-fold cross validation\n",
        "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "scores1 = cross_val_score(model1, x_train, y_train, cv=cv, scoring='accuracy')\n",
        "print(\"Cross Validation Scores: \", scores1)\n",
        "print(\"Average CV Score: \", scores1.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores1))"
      ],
      "metadata": {
        "id": "ou4hGJuWRfE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It helps in being sure that we have dtected all the patterns and that all the data have passed on the model . It is the best way to train.\n",
        "\n",
        "We can get an idea about model over fitting if the accuracy shown goes up and than goes down . This is explained by the fact that the data passed has been used without knwing the general pattren\n",
        "which why it fails in the accuracy test (goes up and than down)"
      ],
      "metadata": {
        "id": "XbH09rIWRjXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Leave-one-out cross validation\n",
        "cv = LeaveOneOut()\n",
        "scores3 = cross_val_score(model1, x, y, cv=cv, scoring='accuracy')\n",
        "print(\"Cross Validation Scores: \", scores3)\n",
        "print(\"Average CV Score: \", scores3.mean())\n",
        "print(\"Number of CV Scores used in Average: \", len(scores3))\n",
        "print (\"number of scores participating\", np.count_nonzero(scores3))"
      ],
      "metadata": {
        "id": "GSms_2HtSAkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same prinipale with cross 10 but here we don't devide data ino 10 batchs but every row is treated as a batch"
      ],
      "metadata": {
        "id": "lfmyB-ZuSF5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the validation curve to check bias and variance, thus underfitting and overfitting\n",
        "LearningCurveDisplay.from_estimator(model1, x_train, y_train, cv=10, scoring='accuracy')"
      ],
      "metadata": {
        "id": "ZYJAfu2PSNtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "vISULATION OF THE VALIDATION CURVE"
      ],
      "metadata": {
        "id": "1HW8mQ_7SYGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest Classifier\n",
        "model2 = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, max_features='sqrt', random_state=42) #default values\n",
        "model2.fit(x_train, y_train)\n",
        "y_pred = model2.predict(x_test)"
      ],
      "metadata": {
        "id": "Wla2ikMrSXjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This uses multiple decison trrees with different samples to get many different results and than by making a vote between all the options we get the final result. It ensures varity and all scenatios coverage when trainning"
      ],
      "metadata": {
        "id": "9rcKtRJySS6T"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z2XhKcLgSsB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}