{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmpI3UQ4II5J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd    # to handle the dataframe\n",
        "pd.set_option('expand_frame_repr', False) #to avoid the multi-lines formatting of the dataframe\n",
        "import numpy as np     # to handle numbers and ndarray"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas is the library we will use to handel our dataFrames\n",
        "\n",
        "data frame has this structure {'Column Name':[list of values] for each column in the csv file}"
      ],
      "metadata": {
        "id": "CraXe7L1ITXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('CSVFileName.csv')"
      ],
      "metadata": {
        "id": "U7n4QvaZIn41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-This is the command to import the csv file after it beeing imported to our collab enviroment, and actually with a simple print(df) it can be printed and you can see what you data has in it (very recommendeed to know what data do you have)\n",
        "\n",
        "**It is a good practice to create a new data set instance after making multiple changeds into the new data set so that you don't lose information**\n",
        "df_Numerical=df (This is possible as df will be already modified ) amnd from now omn you will be using df_values in your work"
      ],
      "metadata": {
        "id": "bJQwlLDzIqxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "05D0Of6ZIn20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Number of Rows, Number of Columns)"
      ],
      "metadata": {
        "id": "JwE8BEujJelA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "9OXAz78CIn0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Know what are the columns in the imported dataframe"
      ],
      "metadata": {
        "id": "n2GCIk81Jp2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for column_name in df.columns:\n",
        "    print(df[column_name])\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "heomEq-6Pr6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This type of for iterations allows you to work on each column if you want to make anymodification on a whole column at once"
      ],
      "metadata": {
        "id": "eQDiRepkPxpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(n)"
      ],
      "metadata": {
        "id": "1zepuoCWInyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first n rows of the dataset"
      ],
      "metadata": {
        "id": "cFI019atJwTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.loc[0].index) # 0 can be replaced with any value of any valid number row\n",
        "df.set_index(np.arange(10,112), inplace=True) # chnahge the imndex from being 1..n into beeing what ver you want (112 must be replaced with the number of rows + first index)\n",
        "print(df.loc[10].index) #\n",
        "print(df.iloc[20:37,0:2]) # rows 20 until 36 and first and second column the third is excluded\n",
        "print(df.loc['15':'17', 'Personality':'Age']) #chose rows 15 until 17"
      ],
      "metadata": {
        "id": "nCzAzYmMInwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instrections to get a specific row or column"
      ],
      "metadata": {
        "id": "1ZlfeduHJ1a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info"
      ],
      "metadata": {
        "id": "EpFW_4ViInty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is used to get general information about the different statistical caracteristics of the dataset"
      ],
      "metadata": {
        "id": "9EpVsDhWKpIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlt_seris =df.groupby(['Column1','Column2','Column3']).Column.mean()"
      ],
      "metadata": {
        "id": "KJCE43rdInrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "groups the data by the Column1 then by Column2 then by Column3\n",
        "\n",
        ".Column must be a numerical value (Float or int)\n",
        "\n",
        "object here stands for String"
      ],
      "metadata": {
        "id": "b8fCwAzTK4Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_split=df.loc[:df.dtypes==object]"
      ],
      "metadata": {
        "id": "yywdiliEInpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract all numerical data (Ignore all categorical data)"
      ],
      "metadata": {
        "id": "ICX2-QnrLX0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_split[column_name].mean())\n",
        "print(num_split[column_name].median())\n",
        "print(num_split[column_name].mode()"
      ],
      "metadata": {
        "id": "WQR3Lw2FL3Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These operations can be applieed on all numerical columns (even in datasets that has both categorical and numerical columns)\n",
        "\n",
        "The column name must be a numerical column"
      ],
      "metadata": {
        "id": "B4tk6nRxL92M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "# Calculating the mean and standard deviation of the parameter \"GStat\":\n",
        "mean = df['Column'].mean()\n",
        "std = df['Column'].std()\n",
        "\n",
        "# Calculating probability density function (PDF)\n",
        "pdf = stats.norm.pdf(df['Column'].sort_values(), mean, std)\n",
        "\n",
        "# Drawing a graph\n",
        "plt.plot(df['Column'].sort_values(), pdf)\n",
        "plt.xlim([5,20])\n",
        "plt.xlabel('Name of column', size=12)\n",
        "plt.ylabel('Frequency', size=12)\n",
        "plt.grid(True, alpha=0.3, linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KgxhCQR3L3Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is used for **ONLY** the same **Numerical Column** all what you have to do is to replace the df['Column'] with df['The Numerical Column that you want to check']\n",
        "\n",
        "It woul be really appreciated if you can make the operation for multiple numerical columns (To better visulaize the given work)"
      ],
      "metadata": {
        "id": "sR7R1FjPMkKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categ_split=df.loc[:df.dtypes=object]"
      ],
      "metadata": {
        "id": "f8Ud_fR4Lctd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract all categorical data (Ignore all numerical data)"
      ],
      "metadata": {
        "id": "odAz5zzwLdU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(categ_split[column_name].mode())\n",
        "print(categ_split[column_name].value_counts())"
      ],
      "metadata": {
        "id": "Bshuqm1QLf2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are the functions that allow you to work on the categorical data"
      ],
      "metadata": {
        "id": "VMxukCowNWbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the range\n",
        "def range_imp(dat):\n",
        "  return (dat.max()-dat.min())\n",
        "\n",
        "range_results = num_split.select_dtypes(include='number').apply(range_imp)\n",
        "range_results\n",
        "\n",
        "def interquartile_range(dat):\n",
        "  return (dat.quantile(0.75)-dat.quantile(0.25))\n",
        "\n",
        "resultsIQR = num_split.select_dtypes(include='number').apply(interquartile_range)\n",
        "resultsIQR"
      ],
      "metadata": {
        "id": "TKXPA35pQDqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are some statistical mesures you need to know and when usoing it just"
      ],
      "metadata": {
        "id": "kzPEDQwiQX4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "dl5wlLxFQDo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statistical"
      ],
      "metadata": {
        "id": "OHzu63DEQjqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_split.boxplot()\n",
        "\n",
        "#Variance\n",
        "num_split.var()\n",
        "\n",
        "#Standard deviation (√©cart type)\n",
        "num_split.std()"
      ],
      "metadata": {
        "id": "iRpxr_jjNb3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funtions to help understand the dispersion of our data"
      ],
      "metadata": {
        "id": "nRZscId5Nwmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Kurtosis\n",
        "num_split.kurtosis()\n",
        "#Skewness\n",
        "num_split.skew()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XrREYPWROCGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These functions allows us to understand the symmetry of our data\n",
        "\n",
        "Check pages 54 and 55 from chapitre 2 in the class room in order to make interpretaions as they will be damanded depending on the dataset that will be offered to you"
      ],
      "metadata": {
        "id": "_cjtheHpOMPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "****You are the best Keep it up nothing will stop us üí™ ‚≠ê****"
      ],
      "metadata": {
        "id": "S8umWNhbOsoG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Us6169B1OE49"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}